{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposition d'algorithme pour le choix des PFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ce notebook est prévu pour être lancé sur le master d'un cluster spark, par exemple avec la commande : **   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" ./spark-1.5.1-bin-hadoop2.6/bin/pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ou en local, par exemple avec par exemple la commande (pour python3) : **   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PYSPARK_PYTHON=/usr/bin/python PYSPARK_DRIVER_PYTHON=/usr/bin/ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" ~/Spark/spark-1.5.1-bin-hadoop2.6/bin/pyspark --master=\"local[4]\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un principe itératif:\n",
    "1. on regarde pour chacune son ou ses projets préférés, puis on détermine tous les groupes valides que l'on peut faire à partir de là.\n",
    "2. si aucune solution n'est retournée, on baisse d'un point les notes maximales (on passe toutes les notes 50 à 49 par exemple) et on recommence au point 1.\n",
    "3. si au moins une solution est retournée, c'est fini. Il reste à choisir la solution en bonne intelligence...\n",
    "\n",
    "De cette manière on cherche à satisfaire chacun au mieux, si ce n'est pas possible on *baisse un peu la barre* pour tout le monde et on recommence. Je trouve que c'est mieux que de chercher à maximiser une fonction globale qui pourrait satisfaire beaucoup la majorité et laisser quelques très déçus.\n",
    "\n",
    "Par ailleurs, cet algorithme propose l'ensemble des (meilleures) possibilités, il n'y a pas d'aléatoire. L'implémentation est (assez) simple, mais un peu longue à tourner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouvelle implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principe de la nouvelle implémentation :  \n",
    "- on part d'une matrice M de booleans (Mij == True <=> le projet_j fait partie des projets préférés de la personne_i) ;\n",
    "- on peut tester si la matrice représente une configuration acceptable (i.e. si chaque personne n'a qu'un seul projet affecté et que les groupes sont tous de 4 personnes sauf un groupe de 3 personnes)\n",
    "- si la matrice n'est pas acceptable, alors on tente de la rendre acceptable en la transformant (on transforme un ou plusieurs True en False)\n",
    "- on continue en testant toutes les possibilités jusqu'à obtenir soit une matrice acceptable, soit une matrice non acceptable (e.g. avec une personne affectée à 0 projets).\n",
    "\n",
    "L'ensemble des possibilités étant très large, on tente de faire des transformation intelligentes et de détecter au plus tôt les configurations qui ne peuvent aboutir à une matrice acceptable, quelque soit les futures transformations appliquées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changement du code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai mis en 'dur' la taille des groupes (un groupe de 3 et sept groupes de 4). Ce qui accélère les opérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suite au mail de Stephan..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai ajouté la possibilité d'avoir trois groupes de 5 sur les projets BNP, SACEM, IPSEN et SFR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "class DataError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_M(df, cut):\n",
    "    '''Transform the initial dataframe into a matrix of bolean M such as:\n",
    "    Mij = True iff project_j is one of the person_i's preferred project\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : the initial dataframe\n",
    "    cut : the value at which a project is considered to be a 'preferred' project\n",
    "    Returns:\n",
    "    --------\n",
    "    A n x p boolean Numpy array.\n",
    "    '''\n",
    "    val = df.values.copy()\n",
    "    val[val > cut] = cut\n",
    "    max_lines = val.max(axis=1)\n",
    "    M = (val.T == max_lines).T\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_and_check_M(M, projects_5):\n",
    "    '''Remove (in-place) some impossible choices (the more and the faster we can find them the better).\n",
    "    Then test for (in)validity\n",
    "    Current cleaning ideas:\n",
    "    (i) removing (setting the column to False) projects with strictly less than 3 people on it\n",
    "    (ii) removing people from projects who are full (i.e. already 4 or 5 (for authorized projs) \n",
    "         people sure on it) ;\n",
    "         may need several passes\n",
    "    Current checking for invalidity ideas:\n",
    "    (i) there exists i such that sum_i Mij == 0\n",
    "    (ii) there is a project with more than 4 people (sure), on it\n",
    "    (iii) there is more than one project with exactly 3 people on it (check on totally defined projects)\n",
    "    Current checking for validity ideas:\n",
    "    (i) sum_j Mij == 1 for all i\n",
    "    (ii) [sum_i Mij for i in 1..n] contains only 0s, 4s, 5s and at most one 3.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : numpy boolean array to be cleaned\n",
    "    projects_5 : a p Numpy boolean array with True where the project can hold a team of 5\n",
    "    Returns:\n",
    "    --------\n",
    "    -1 if invalid\n",
    "    +1 if valid\n",
    "     0 if we do not know and must continue our search\n",
    "    '''\n",
    "    # Cleaning.. \n",
    "    sum_cols = M.sum(axis=0)\n",
    "    sum_lines = M.sum(axis=1)\n",
    "    # .. (i)\n",
    "    M[:, sum_cols < 3] = False\n",
    "    # .. (ii)\n",
    "    flag = True\n",
    "    while flag:\n",
    "        pers_sure = sum_lines == 1\n",
    "        min_pers_on_projects = M[pers_sure].sum(axis=0)\n",
    "        full_projs = np.logical_and(min_pers_on_projects >= 4,\n",
    "                                    np.logical_or(np.invert(projects_5),\n",
    "                                                  min_pers_on_projects >= 5))\n",
    "        sub_M = M[np.ix_(np.invert(pers_sure), full_projs)]\n",
    "        flag = np.any(sub_M) # if there is something to change\n",
    "        #print(\"flag is {}...\".format(flag))\n",
    "        if flag:\n",
    "            M[np.ix_(np.invert(pers_sure), full_projs)] = False\n",
    "            \n",
    "    # Checking... \n",
    "    sum_lines = M.sum(axis=1)\n",
    "    sum_cols = M.sum(axis=0)\n",
    "    pers_sure = sum_lines == 1\n",
    "    min_pers_on_projects = M[pers_sure].sum(axis=0)\n",
    "    # projects already defined = projects which are the only choice of the people on it\n",
    "    # i.e. projects that will not be reduced since it would make a person project-less\n",
    "    already_defined_projects = min_pers_on_projects == sum_cols\n",
    "    # .. if invalid\n",
    "    # (i) everyone got at least one project\n",
    "    # (ii) no project exceed maximum limit\n",
    "    # (iii) no more than one project with exactly three people on it\n",
    "    if np.any(sum_lines == 0) or \\\n",
    "    np.any(np.logical_and(min_pers_on_projects > 4,\n",
    "           np.logical_or(np.invert(projects_5),\n",
    "                         min_pers_on_projects > 5))) or \\\n",
    "    sum(sum_cols[already_defined_projects] == 3) > 1:\n",
    "        return -1\n",
    "    \n",
    "    # .. if valid\n",
    "    if np.all(pers_sure) and \\\n",
    "    (not [1 for s in sum_cols if s not in [0, 4, 5, 3]]) and \\\n",
    "    (np.sum(sum_cols == 3) <= 1):\n",
    "        return 1\n",
    "    \n",
    "    # If we do not know...\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_M(M):\n",
    "    '''returns a list of copies of the matrix M with each correspond to a step towards\n",
    "    a solution\n",
    "    Best ideas so far : \n",
    "    (i) we pick the person with the fewest number of preferred projects (k > 1) and\n",
    "        create k different possible matrices\n",
    "    '''\n",
    "    sum_lines = M.sum(axis=1)\n",
    "    sum_lines[sum_lines == 1] = 32768 # arbitrary large value, must be larger than the number of projects\n",
    "    pers = np.argmin(sum_lines)\n",
    "    for j, proj in enumerate(M[pers]):\n",
    "        if proj:\n",
    "            new_M = M.copy()\n",
    "            new_M[pers] = 0\n",
    "            new_M[pers, j] = True\n",
    "            yield new_M\n",
    "    #Can we assure that the cleaned version will yield different matrices ??? \n",
    "    # -> In that case, yes since the cleaned matrices will either be different or invalid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_check_generate(M, p5_broad):\n",
    "    '''Function to be mapped over the RDD'''\n",
    "    check = clean_and_check_M(M, p5_broad.value)\n",
    "    # if the matrix is valid\n",
    "    if check == 1:\n",
    "        return [(True, M)]\n",
    "    # if the matrix may be valid but need further investigation\n",
    "    elif check == 0:\n",
    "        return [(False, m) for m in next_M(M)]\n",
    "    # if the matrix is invalid\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction principale de l'algorithme, qui explore l'arbre des possibilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_groups(M, projects_5):\n",
    "    '''Returns a list of acceptable projects\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : an nxp Numpy boolean array representing preferred projects per persons\n",
    "    projects_5 : a p Numpy boolean array with True where the project can hold a team of 5\n",
    "    Returns:\n",
    "    --------\n",
    "    a list of valid numpy arrays \n",
    "    '''\n",
    "    sols = []\n",
    "    # We make an RDD\n",
    "    Ms = sc.parallelize([M])\n",
    "    p5_broad = sc.broadcast(projects_5)\n",
    "    # function of 1 parameter to be passed in a flatmap later\n",
    "    f = lambda m: clean_check_generate(m, p5_broad)\n",
    "    # keeps track of length of the RDD (without having to call an expensive 'count')\n",
    "    count = 1\n",
    "    while count > 0:\n",
    "        print(\" New iteration, ToCheck={}, Found={}.\".format(count, len(sols)))\n",
    "        count = 0\n",
    "        #print('We check \\n {}'.format(m))\n",
    "        NewMs = Ms.flatMap(f)\n",
    "        for i, ms in NewMs.groupByKey().collect():\n",
    "            if not i:\n",
    "                Ms = sc.parallelize(ms)\n",
    "                count += len(ms)\n",
    "            else:\n",
    "                sols = sols + ms.data\n",
    "    return sols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction utile qui cappe les valeurs à une certaine valeur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haircut(dat, n):\n",
    "    ''' Caps all numbers at n'''\n",
    "    dat_cap = dat.applymap(lambda x: min(n, x))\n",
    "    return dat_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme complet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def algo(dat, project_5, cap=50):\n",
    "    '''Main algorithm (recursive)'''\n",
    "    # If the data is correct, this should not happen\n",
    "    # put it there to prevent infinite loop\n",
    "    if cap == 1:\n",
    "        raise DataError('Bad data, no solution is possible')\n",
    "    print(\"Run for cap={}...\".format(cap))\n",
    "    m = make_M(dat, cap)\n",
    "    sol = make_groups(m, projects_5)    \n",
    "    if not sol:\n",
    "        return algo(dat, projects_5, cap=cap-1)\n",
    "    return sol, cap   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec nos données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import et nettoyage des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except:\n",
    "    from io import StringIO\n",
    "r = requests.get('https://docs.google.com/spreadsheets/d/1hUWvO8wyEJL-_SkhgpdrwdYiDL7XQdrbTkcp21py8Lw/export?format=csv&id=1hUWvO8wyEJL-_SkhgpdrwdYiDL7XQdrbTkcp21py8Lw&gid=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat_bgd = pd.read_csv(StringIO(r.text), skiprows=1, index_col='Nom')\n",
    "dat_bgd = dat_bgd.loc[:, 'Clustaar':'Plume Labs']\n",
    "dat_bgd = dat_bgd.fillna(0)\n",
    "dat_bgd = dat_bgd.loc[[i for i in dat_bgd.index if isinstance(i, str)], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projets où un groupe de 5 personnes est authorisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects_5 = pd.Series(data=np.array([False] * 15), index=dat_bgd.columns)\n",
    "projects_5['BNP'] = True\n",
    "projects_5['SACEM'] = True\n",
    "projects_5['IPSEN'] = True\n",
    "projects_5['SFR 1'] = True\n",
    "projects_5['SFR 2'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test s'il y a bien 31 personnes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 personnes ont répondu.\n",
      "Il faut ajouter 1 personne(s).\n"
     ]
    }
   ],
   "source": [
    "n, p = dat_bgd.shape\n",
    "print('{} personnes ont répondu.'.format(n))\n",
    "if n < 31:\n",
    "    print('Il faut ajouter {} personne(s).'.format(31-n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il manque Cynthia (il faut qu'il y ait 31 personnes sinon l'algo ne trouvera rien !):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, p = dat_bgd.shape\n",
    "if n < 31:\n",
    "    cv = pd.Series(name='Cynthia VARIEUX', index=dat_bgd.columns, data=[100./15] * 15)\n",
    "    dat_bgd = dat_bgd.append(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que la somme des notes fasse 100 et qu'aucun projet ne se voit affecter plus de 50 points, on répartit :\n",
    "* les points manquants entre tous les projets ;\n",
    "* les points au dessus de 50 entre les autres projet.\n",
    "\n",
    "Plusieurs passes peuvent être nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_bad(df):\n",
    "    bad_sums = np.abs(dat_bgd.sum(axis=1) - 100) > 0.001 \n",
    "    bad_cells = dat_bgd > 50\n",
    "    return np.any(bad_sums) or np.any(bad_cells)\n",
    "\n",
    "while is_bad(dat_bgd):\n",
    "    # cut à 50:\n",
    "    bad_cells = dat_bgd > 50\n",
    "    dat_bgd[bad_cells] = 50\n",
    "    # repartition des points manquants (hors des cells déjà à 50)\n",
    "    pts_a_repartir = 100 - dat_bgd.sum(axis=1)\n",
    "    non_max_cells = dat_bgd < 50\n",
    "    denominator = non_max_cells.sum(axis=1)\n",
    "    to_add = (non_max_cells.T * np.array(pts_a_repartir / denominator)).T\n",
    "    dat_bgd = dat_bgd + to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécution de l'algorithme (attention, ça peut être long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run for cap=50...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=49...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=48...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=47...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=46...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=45...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=44...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=43...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=42...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=41...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=40...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=39...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=38...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=37...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=36...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=35...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=34...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=33...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=32...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=31...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      "Run for cap=30...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      " New iteration, ToCheck=2, Found=0.\n",
      " New iteration, ToCheck=4, Found=0.\n",
      " New iteration, ToCheck=8, Found=0.\n",
      " New iteration, ToCheck=16, Found=0.\n",
      " New iteration, ToCheck=28, Found=0.\n",
      " New iteration, ToCheck=48, Found=0.\n",
      " New iteration, ToCheck=86, Found=0.\n",
      " New iteration, ToCheck=173, Found=0.\n",
      " New iteration, ToCheck=314, Found=0.\n",
      " New iteration, ToCheck=586, Found=0.\n",
      " New iteration, ToCheck=1048, Found=0.\n",
      " New iteration, ToCheck=1832, Found=0.\n",
      " New iteration, ToCheck=1734, Found=0.\n",
      " New iteration, ToCheck=2432, Found=0.\n",
      " New iteration, ToCheck=2171, Found=0.\n",
      " New iteration, ToCheck=1544, Found=0.\n",
      "Run for cap=29...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      " New iteration, ToCheck=2, Found=0.\n",
      " New iteration, ToCheck=4, Found=0.\n",
      " New iteration, ToCheck=8, Found=0.\n",
      " New iteration, ToCheck=16, Found=0.\n",
      " New iteration, ToCheck=28, Found=0.\n",
      " New iteration, ToCheck=48, Found=0.\n",
      " New iteration, ToCheck=86, Found=0.\n",
      " New iteration, ToCheck=173, Found=0.\n",
      " New iteration, ToCheck=314, Found=0.\n",
      " New iteration, ToCheck=586, Found=0.\n",
      " New iteration, ToCheck=1048, Found=0.\n",
      " New iteration, ToCheck=1832, Found=0.\n",
      " New iteration, ToCheck=1734, Found=0.\n",
      " New iteration, ToCheck=2432, Found=0.\n",
      " New iteration, ToCheck=2171, Found=0.\n",
      " New iteration, ToCheck=1544, Found=0.\n",
      "Run for cap=28...\n",
      " New iteration, ToCheck=1, Found=0.\n",
      " New iteration, ToCheck=2, Found=0.\n",
      " New iteration, ToCheck=4, Found=0.\n",
      " New iteration, ToCheck=8, Found=0.\n",
      " New iteration, ToCheck=16, Found=0.\n",
      " New iteration, ToCheck=30, Found=0.\n",
      " New iteration, ToCheck=52, Found=0.\n",
      " New iteration, ToCheck=104, Found=0.\n",
      " New iteration, ToCheck=170, Found=0.\n",
      " New iteration, ToCheck=341, Found=0.\n",
      " New iteration, ToCheck=648, Found=0.\n",
      " New iteration, ToCheck=1161, Found=0.\n",
      " New iteration, ToCheck=2144, Found=0.\n",
      " New iteration, ToCheck=4199, Found=0.\n",
      " New iteration, ToCheck=7115, Found=0.\n",
      " New iteration, ToCheck=12225, Found=0.\n",
      " New iteration, ToCheck=19465, Found=0.\n",
      " New iteration, ToCheck=27582, Found=0.\n",
      " New iteration, ToCheck=28543, Found=12.\n",
      " New iteration, ToCheck=19342, Found=19.\n",
      " New iteration, ToCheck=15726, Found=31.\n",
      "enlapsed time = 0:00:39.806741\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.datetime.now()\n",
    "sols, cut = algo(dat_bgd, projects_5)\n",
    "t1 = datetime.datetime.now()\n",
    "print('enlapsed time = {}'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_M_df(M, df):\n",
    "    sol_df = pd.DataFrame(data=M, columns=df.columns, index=df.index)\n",
    "    sol_serie = sol_df.apply(lambda s: s.argmax(), axis=1)\n",
    "    return sol_serie\n",
    "\n",
    "def convert_sols_df(sols, df):\n",
    "    sol = pd.DataFrame(data=[convert_M_df(M, df) for M in sols])\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tab = convert_sols_df(sols, dat_bgd)\n",
    "#final_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_tab.to_csv('sols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_row(row):\n",
    "    d = {proj: [] for proj in dat_bgd.columns}\n",
    "    for name, proj in zip(row.index, row):\n",
    "        d[proj].append(name)\n",
    "    return d\n",
    "\n",
    "def extract_teams(final_tab):\n",
    "    for row in final_tab.index:\n",
    "        print(\"\\nSolution {}:\".format(row))\n",
    "        d = from_row(final_tab.loc[row])\n",
    "        for proj in dat_bgd.columns:\n",
    "            print(\"Projet {:15s}: {}\".format(proj, ', '.join(d[proj])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_teams(final_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all the above information into a csv file (to be imported in a spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('output.csv', 'w') as f:\n",
    "    f.write('Output de l\\'algorithme (base de discussion).\\n'\n",
    "            'Date de génération {}\\n.'.format(datetime.datetime.now()))\n",
    "    f.write('Le cut a été effectué à {} points.\\n'.format(cut))\n",
    "    f.write('Source : XXX\\n'\n",
    "            'Note 1 : les personnes n\\'ayant pas rempli le tableau sont ajoutées '\n",
    "            'et sont supposées affecter un poid égal à chaque projet.\\n'\n",
    "            'Note 2 : les personnes n\\'ayant pas affecté 100 points sont supposées '\n",
    "            'affecter leur restant de points de manière équitable entre tous les '\n",
    "            'projets (en respectant la limite de 50 points max par projet).\\n'\n",
    "            'Note 3 : un seul groupe de 3 personnes permis, groupes de 5 personnes permis sur les'\n",
    "            ' projets IPSEN, SACEM, SFR 1, SFR 2, BNP\\n\\n'\n",
    "            'TABLEAU RECAPITULATIF DES SOLUTIONS\\n')\n",
    "    f.write(final_tab.to_csv(None))\n",
    "    f.write('\\n\\nDETAILS DES SOLUTIONS')\n",
    "    for row in final_tab.index:\n",
    "        f.write('\\nSOLUTION N°{}\\n'.format(row))\n",
    "        f.write('Projet,Equipe\\n')\n",
    "        d = from_row(final_tab.loc[row])\n",
    "        for proj in dat_bgd.columns:\n",
    "            f.write('{},{}\\n'.format(proj, ','.join(d[proj])))          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
