{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exericce 6 - dependances honoraires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspiré du travail uillaume Mohr et Aurelien Galicher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################traitement du fichier rpps_tab3.csv = nbr medecins par departement / annee/ specialité\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "File data_cours6/rpps_tab3.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2c80e4848e71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"###################################traitement du fichier rpps_tab3.csv = nbr medecins par departement / annee/ specialité\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_med\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_cours6/rpps_tab3.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf_med\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf_med\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_med\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annee'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2014\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdf_med\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3229)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6042)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File data_cours6/rpps_tab3.csv does not exist"
     ]
    }
   ],
   "source": [
    "#recuperation et traitement de rpps_tab3.csv\n",
    "\n",
    "print(\"###################################traitement du fichier rpps_tab3.csv = nbr medecins par departement / annee/ specialité\")\n",
    "df_med = pd.read_csv(\"data_cours6/rpps_tab3.csv\")\n",
    "df_med= df_med[df_med['annee'] == 2014]\n",
    "print df_med.ix[55:65,1]\n",
    "# récupération du code département.\n",
    "regx = re.compile(r'([0-9]\\w[0-9]?) -')\n",
    "df_med['dep'] = list(map(lambda x: regx.search(x).groups()[0] if regx.search(x) else None , list(df_med['zone_inscription'].astype(str))))\n",
    "df_med = df_med.drop('annee',1) #removing annee filtree a 2014\n",
    "print df_med.head()\n",
    "df_med= df_med.groupby(['dep','specialite']).sum()\n",
    "print df_med\n",
    "df_med = df_med.reset_index()#reindexation dan l ordre\n",
    "\n",
    "\n",
    "#affichage sous forme tableau croise dynamique avec lignes(index) = dep et colonnes = specialites\n",
    "pivot_med = df_med.pivot(index='dep', columns='specialite', values='effectifs')\n",
    "print type(pivot_med)#le resultat est toujours une df\n",
    "print \"pivot: \", '\\n',pivot_med.head()\n",
    "\n",
    "#operation inverse du pivot, on revient au format en 3 colonnes initial\n",
    "print \"pivot_med.stack(): \", '\\n'\n",
    "print pivot_med.stack()\n",
    "\n",
    "#proportion de specialistes sur tous praticiens et de geriatres sur tous praticiens\n",
    "pivot_med['r_spe_tot'] = pivot_med['Spécialistes'] / pivot_med['Ensemble des spécialités d\\'exercice']\n",
    "pivot_med['r_ger_tot'] = pivot_med['Gériatrie'] / pivot_med['Ensemble des spécialités d\\'exercice']\n",
    "print pivot_med.head()\n",
    "#analyse structure de df type pivot\n",
    "print pivot_med.columns.values #affichage des specialites\n",
    "print pivot_med.index.values #affichage des departelents\n",
    "#on observe que les champs affichés : specialite et dep ne sont ni dans les index ni dans les colonnes , informations en plus\n",
    "\n",
    "#histogramme a corriger pour affichage pour chaque departement, pour le moment les deps sont regroupes par valeur\n",
    "fig, ax = plt.subplots()\n",
    "pivot_med['r_ger_tot'].hist(figsize=(16,6), bins=105)\n",
    "plt.title('repartition du ratio geriatre/ensemble medecin par departement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pour utiliser le fichier de densite des medecins par specialite,\n",
    "# on telecharge format csv a partir du site http://www.data.drees.sante.gouv.fr/TableViewer/tableView.aspx?ReportId=1155\n",
    "#on recupere ainsi la fichier rpps-medecin-tab7-densite-2013-14-15-v1_51872514070569\n",
    "print \"###########Chargement fichier rpps des densites de medecin par dep, specialite en colonnes ########################\"\n",
    "rpps = pd.read_csv('data_cours6/rpps-medecin-tab7-densite-2013-14-15-v1_51878339473545.csv',\n",
    "                    skiprows=[0, 1, 2, 3, 5]) #encoding='latin9', est a eviter a ce moment la car le traitement avec regex ulterieur ne passe plus\n",
    "# sans preciser le type d'encodage on a des caracteres bizarres : rpps = pd.read_csv('data_cours6/rpps-medecin-tab7-densite-2013-14-15-v1_51878339473545.csv', skiprows=[0, 1, 2, 3, 5])\n",
    "#on a les infos dabord par region puis si on descend dans le fichier, on les a par departement\n",
    "rpps.rename(columns={'SPECIALITE': 'ZoneInscription'}, inplace=True)  #renommage d une colonne existante\n",
    "print \" rpps: \",'\\n', rpps.ix[:5,:14], '\\n','\\n'\n",
    "\n",
    "#ici on veut creer une nouvelle colonne qui contienne les codes de departements\n",
    "regx = re.compile(r'([0-9]\\w[0-9]?) -') #ici on cree le pattern regex que l on va appliquer au cellules de la colonne ZoneIncription\n",
    "rpps['dep'] = list(map(lambda x: regx.search(x).groups()[0] if regx.search(x) else None , list(rpps['ZoneInscription'].astype(str))))\n",
    "#df_med.dropna() #removing non dep\n",
    "print \" rpps: \", rpps.ix[36:45,[0,-1]], '\\n','\\n'\n",
    "print type(rpps)\n",
    "print rpps.columns.values\n",
    "#affichage geriatre par departement\n",
    "print \"affichage geriatre par departement: \",'\\n'\n",
    "rpps_ger = rpps[['G\\xe9riatrie','dep']]\n",
    "rpps_ger = rpps_ger.dropna()\n",
    "print rpps_ger.head()\n",
    "\n",
    "####tentative de tranformation en int de la colonne dep\n",
    "rpps_ger['new_dep'] =  rpps_ger.apply(lambda r: r[\"dep\"] if (r[\"dep\"] != \"2A\" or r[\"dep\"] != \"2B\") else 0 , axis = 1)\n",
    "new_rpps_ger = rpps_ger[['G\\xe9riatrie','new_dep']]\n",
    "#new_rpps_ger['new_dep'] = new_rpps_ger.apply(lambda r: int(r['new_dep']) , axis = 1)\n",
    "\n",
    "print new_rpps_ger.ix[36:45,:]\n",
    "fig2, ax = plt.subplots()\n",
    "new_rpps_ger['G\\xe9riatrie'].hist(figsize=(16,6), bins=105)\n",
    "plt.title('repartition densite de geriatre departement')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"###########Chargement fichier depassements honoraires par departement########################\"\n",
    "#On dispose aussi dun fichier precisant les depassements dhonoraire par departement\n",
    "#data = pd.read_csv('Honoraires_totaux_des_professionnels_de_sante_par_departement_en_2013' , sheetname =\"Specialistes\")\n",
    "\n",
    "data = pd.io.excel.read_excel(\"data_cours6/Honoraires_totaux_des_professionnels_de_sante_par_departement_en_2013.xls\", sheetname =\"Specialistes\", na_values = \"nc\")\n",
    "#print data.head()\n",
    "print '\\n', '\\n', '\\n'\n",
    "data = data[['SPECIALISTES','DEPARTEMENT', 'DEPASSEMENTS (euros)','DEPASSEMENT MOYEN (euros)','NOMBRE DE DEPASSEMENTS', 'EFFECTIFS']]\n",
    "print \"Honoraires: \",'\\n',data.head()\n",
    "print '\\n', '\\n', '\\n'\n",
    "\n",
    "print \"Drop des Nan\"\n",
    "data = data.dropna(subset = ['DEPASSEMENTS (euros)', 'DEPASSEMENT MOYEN (euros)'])\n",
    "# exemple a prendre si plusierus valeurs a supprimer df[df['Behavior'].str.contains(\"nt\", na=False)]\n",
    "print data[:15]\n",
    "print '\\n', '\\n', '\\n'\n",
    "\n",
    "print data[:5]\n",
    "print '\\n', '\\n', '\\n'\n",
    "data = data.groupby(['DEPARTEMENT']).sum()\n",
    "print data.head()\n",
    "data = data[['NOMBRE DE DEPASSEMENTS']]\n",
    "print data.head()\n",
    "\n",
    "fig3, ax = plt.subplots()\n",
    "data['NOMBRE DE DEPASSEMENTS'].hist(figsize=(16,6), bins=105)\n",
    "plt.title('repartition depassements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print \"###########Chargement fichier N201508 des depassements honoraires ########################\"\n",
    "#On charge un deuxieme fichier du sitehttps://www.data.gouv.fr/fr/datasets/depenses-d-assurance-maladie-hors-prestations-hospitalieres-par-caisse-primaire-departement/\n",
    "#Avec ce fichier on a les depassements d honoraire par specialite mais a cheval entre 2014 et 2015 et on a pas de localisation\n",
    "dep = pd.read_csv('data_cours6/N201508.csv', encoding='latin9', sep=';',decimal=',',thousands='.',dtype={'dep_mon':float})\n",
    "print \"rep: \",'\\n', dep.ix[:5,:], '\\n','\\n'\n",
    "print dep.shape\n",
    "dep['count_dep']= list(map(lambda x: 1 if x > 0 else 0, dep['dep_mon']))\n",
    "dep.ix[:5,:]\n",
    "print \"dep.shape\",dep.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
